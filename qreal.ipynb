{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b6d8a8-f688-4279-80d8-a2a3d0afb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import qutip\n",
    "from qutip import *\n",
    "from numpy.random import *\n",
    "from qutip.measurement import measure, measurement_statistics\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "# from qutip.states import ket2dm, basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252b9017-13c3-4838-b83b-a79b8b11500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "\n",
    "    # this is an M-ary tree of depth N, i.e. it has M**(N+1) - 1 nodes in total\n",
    "    # each node corresponds to a measurement history,\n",
    "    # i.e. a list x_j = [k_1, k_2, ... k_j] of measurement outcomes.\n",
    "\n",
    "    \n",
    "    # initialize with each node at 0\n",
    "    def __init__(self, M, N):\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.alpha = 0\n",
    "        if N == 1:\n",
    "            self.children = None\n",
    "        else:\n",
    "            self.children = [DecisionTree(M, N-1)]*M\n",
    "        #self.tree = self.makeRandTree(M, N)\n",
    "\n",
    "    # get the value of alpha corresponding to some measurement history x (partial or complete)\n",
    "    def get_alpha(self, x):\n",
    "        r = self\n",
    "        for j in x:\n",
    "            r = r.children[j]\n",
    "            \n",
    "        return r.alpha\n",
    "\n",
    "    # adds a normally-distributed term to each node in the tree\n",
    "    # make sure to take a deepcopy of the tree, so the original tree is preserved\n",
    "    # i may revert to the former tree, depending on the value of the loss function\n",
    "    def tweak(self, std):\n",
    "        mean = [0, 0]\n",
    "        std_matrix = std*np.array([[1, 0], [0, 1]])\n",
    "        noise = normal(mean, std_matrix)\n",
    "        self.alpha = self.alpha + noise[0][0] + 1j*noise[1][1]\n",
    "        if self.children != None:\n",
    "            for j in self.children:\n",
    "                j.tweak(std)\n",
    "\n",
    "    # converts a complete measurement history (N elements) to an integer, in an\n",
    "    # unambiguous and reversible manner, so that i can use it as a key for a dict\n",
    "    # this hashing protocol only works on complete histories\n",
    "def xhash(x, M):\n",
    "    h = 0\n",
    "    for j in range(len(x)):\n",
    "        h += x[j] * M**j\n",
    "    return h\n",
    "\n",
    "    # inverse of xhash()\n",
    "def unhash(h, M, N):\n",
    "    x = []\n",
    "    j = 0\n",
    "    for j in range(N):\n",
    "        rem = h % M**(j+1)\n",
    "        x.append(int(rem/(M**j)))\n",
    "        h -= rem\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4961ba4d-eaef-418c-b004-f9b3d3c0c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given M and N, gives a list of length M**N, such that each element is a list of length N, containing\n",
    "# ints between 0 and M-1\n",
    "# gives every possible complete measurement history\n",
    "def make_xs(M, N) -> list:\n",
    "    if N == 1:\n",
    "        return [[j] for j in range(M)]\n",
    "    else:\n",
    "        xsm = make_xs(M, N-1)\n",
    "        res = []\n",
    "        for xm in xsm:\n",
    "            for j in range(M):\n",
    "                xm.append(j)\n",
    "                res.append(xm.copy())\n",
    "                xm.pop()\n",
    "        return res\n",
    "        \n",
    "# takes a decision tree, a dict of input states, and a code key (an int pointing to a specific input state)\n",
    "# yields the measurement history, hashed\n",
    "# this is a pseudorandom function\n",
    "def process(tree: DecisionTree, code: dict, code_index: int, sigma: int) -> int:\n",
    "\n",
    "    N = tree.N\n",
    "    M = tree.M\n",
    "    projs = [qutip.states.ket2dm(qutip.states.basis(M, j)) for j in range(M)] # single-mode projectors, |j><j|\n",
    "\n",
    "    x = [] # x is the measurement history\n",
    "    #state = ket2dm(coherent(M, code[code_index]))\n",
    "    #state = state.depolarize(\n",
    "    for _ in range(N):\n",
    "        alpha = tree.get_alpha(x) # parameter for displacement D(\\alpha)\n",
    "        gamma = normal(0, sigma) # stochastic variable from a normal distribution, mean 0 and std sigma\n",
    "        # sigma = 0 is valid input (it just always yields the mean)\n",
    "        state = coherent(M, code[code_index]/sqrt(N)*exp(1j*gamma) + alpha)\n",
    "        # this is the coherent state |\\beta_i/sqrt(N) + \\alpha>\n",
    "        [outcome, _] = measure(state, projs) # measure in the (truncated) number basis\n",
    "        \n",
    "        x.append(outcome)\n",
    "\n",
    "    return xhash(x, M) # convert history to int\n",
    "\n",
    "# takes a decision tree, and runs the circuit Q times with the tree.\n",
    "# generates the decision table (maps measurement history -> prediction)\n",
    "# yields the loss (total number of mispredictions)\n",
    "# inb4 is this loss? (yes)\n",
    "def loss(tree, code, Q, priors, sigma):\n",
    "    M = tree.M\n",
    "    N = tree.N\n",
    "    codewords = [randint(len(code)) for _ in range(Q)] # list of input states\n",
    "    table = {}\n",
    "    meas = {}\n",
    "    outcomes = []\n",
    "    xs = [xhash(x, M) for x in make_xs(M, N)]\n",
    "    for j in xs:\n",
    "        meas[j] = [0]*len(code)\n",
    "        # meas is a dict of lists. each entry corresponds to a measurement outcome,\n",
    "        # and each entry thereof to an input state\n",
    "        # each entry thereof counts how many times this input-output pair was observed\n",
    "            \n",
    "    for j in range(Q):\n",
    "        #code_in = code[randint(len(code))]\n",
    "        outcome = process(tree, code, codewords[j], sigma) # run the circuit and obtain outcome\n",
    "        meas[outcome][codewords[j]] += 1\n",
    "        outcomes.append(outcome)\n",
    "        # the outcome is recorded in two different ways\n",
    "\n",
    "    for x in xs:\n",
    "        posteriors = [meas[x][j]*priors[j] for j in range(len(code))]\n",
    "        # this is the (unnormalized) prob. P(x|y), where y is input state and x is measurement outcome\n",
    "        \n",
    "        \n",
    "        # this is the input codeword that maximizes the likelihood of the given measurement\n",
    "        table[x] = posteriors.index(max(posteriors)) # if there are shared first-places, it just picks one of them\n",
    "        # probably the first in the list (lowest code index)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for j in range(Q):\n",
    "        pred = table[outcomes[j]] # what does the decision table believe the input state is?\n",
    "        error = (pred != codewords[j]) # is the decision table wrong?\n",
    "        loss += error\n",
    "    return loss # total number of misidentifications\n",
    "\n",
    "\n",
    "\n",
    "M = 2# dimension of Hilbert space. This is a truncated Fock state, with the basis (|0>, |1>, ... |M-1>).\n",
    "# \n",
    "N = 5 # depth of circuit, including the root node. This is also the number of detectors.\n",
    "beta = 5e-1 # this is a small parameter to ensure the coherent states are \"weak\"\n",
    "Q = 1000 # number of circuit runs per tree\n",
    "# parameters of some coherent states to distinguish between. I will generally try to handle/store only the indices\n",
    "# (0, 1 ...) when possible because they're lighter than complex values.\n",
    "code = {\n",
    "    0: beta,\n",
    "    1: beta*1j,\n",
    "    2: -beta,\n",
    "    3: -beta*1j\n",
    "}\n",
    "\n",
    "# prior probabilities of the input states. just a uniform for now\n",
    "priors = {}\n",
    "for j in range(len(code)):\n",
    "    priors[j] = 1/len(code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3496348f-b737-477e-95d7-0ccbfc3de693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(sigma):\n",
    "    Ni = 50 # number of trees to generate (minus 1)\n",
    "    # equivalently, number of iterations to run the optimization\n",
    "    \n",
    "    print(\"starting\")\n",
    "    tree = DecisionTree(M, N)\n",
    "    cur_loss = loss(tree, code, Q, priors, sigma)\n",
    "    accuracies = [1-cur_loss/Q]\n",
    "    accepts = []\n",
    "    counter = 1\n",
    "    for _ in range(Ni):\n",
    "        new_tree = deepcopy(tree)\n",
    "        new_tree.tweak(0.1) # add gaussian term to each node in tree\n",
    "        new_loss = loss(new_tree, code, Q, priors, sigma)\n",
    "        accuracies.append(1-new_loss/Q)\n",
    "        if new_loss < cur_loss: # if the new tree is better than the existing, it replaces it.\n",
    "            # subsequent random steps are taken from this as starting position\n",
    "            tree = deepcopy(new_tree)\n",
    "            cur_loss = new_loss\n",
    "            accepts.append(1)\n",
    "    \n",
    "        else:\n",
    "            accepts.append(0)\n",
    "        print(f\"{counter}/{Ni}\")\n",
    "        counter += 1\n",
    "    \n",
    "    print(\"done!\")\n",
    "    plt.figure(1)\n",
    "    plt.plot(list(range(Ni+1)), accuracies, \"r.\")\n",
    "    plt.hlines(1/len(code), plt.xlim()[0], plt.xlim()[1], linestyle = \"--\", color = \"k\", label = \"random guess\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(f\"Training a tree on std {sigma}\")\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(list(range(Ni)), accepts, 'b.')\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ba3915-9e9a-44a4-bcc0-a13c099c6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tree, sigma):\n",
    "    Nt = 50\n",
    "    accuracies = []\n",
    "    for _ in range(Nt):\n",
    "        accuracies.append(1-loss(tree, code, Q, priors, sigma)/Q)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(list(range(Nt)), accuracies, 'g.')\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(f\"Testing a tree on std {sigma}\")\n",
    "    return sum(accuracies)/len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40cdd58-8d90-425a-90d4-297242d841c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a tree optimized for a noisefree system\n",
    "# tree_pure, accuracies_pure = optimize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1f31c-e449-4e75-b945-4f8982fab235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.08]\n",
      "starting\n",
      "1/50\n",
      "2/50\n"
     ]
    }
   ],
   "source": [
    "Ns = 2\n",
    "sigmas = np.linspace(0, 0.08, Ns)\n",
    "print(sigmas)\n",
    "\n",
    "trees = []\n",
    "for s in sigmas:\n",
    "    trees.append(optimize(s))\n",
    "\n",
    "accs = []\n",
    "for j in range(Ns):\n",
    "    accs.append([])\n",
    "    for k in range(Ns):\n",
    "        accs[j].append(test(trees[j], sigmas[k]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(accs)\n",
    "plt.colorbar()\n",
    "plt.ylabel(\"Training std\")\n",
    "plt.xlabel(\"Testing std\")\n",
    "ax.set_xticks(range(len(sigmas)), labels=sigmas)\n",
    "ax.set_yticks(range(len(sigmas)), labels=sigmas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b41423-42b5-4e74-a138-24d8cd711c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 4], [0, 1]]\n",
    "b = [3, 4]\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(a)\n",
    "ax.set_xticks(range(len(b)), labels=b)\n",
    "ax.set_yticks(range(len(b)), labels=b)\n",
    "plt.xlabel(\"Training sigma\")\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370ce53-ad3c-462e-9735-bfbc18162092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605769b-8ba4-471c-9b60-996da8cc3110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503f06f-89a6-440e-ad48-99a7e139eb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09d666-a997-4519-a252-acf39f9f29f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qreal)",
   "language": "python",
   "name": "qreal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
